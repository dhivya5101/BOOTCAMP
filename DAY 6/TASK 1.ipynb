{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2421805-2982-41ad-9754-e78c8771e06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 57ms/step - loss: 81210630144.0000 - mae: 243101.1875 - val_loss: 94133288960.0000 - val_mae: 269962.9688\n",
      "Epoch 2/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 83388383232.0000 - mae: 247620.9844 - val_loss: 94132912128.0000 - val_mae: 269962.3125\n",
      "Epoch 3/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 84959092736.0000 - mae: 247325.0938 - val_loss: 94132404224.0000 - val_mae: 269961.4688\n",
      "Epoch 4/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 84724981760.0000 - mae: 248145.2344 - val_loss: 94131716096.0000 - val_mae: 269960.2500\n",
      "Epoch 5/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 84910718976.0000 - mae: 248252.6562 - val_loss: 94130749440.0000 - val_mae: 269958.6250\n",
      "Epoch 6/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 87816331264.0000 - mae: 254916.6406 - val_loss: 94129463296.0000 - val_mae: 269956.5312\n",
      "Epoch 7/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 85373730816.0000 - mae: 249876.8750 - val_loss: 94127718400.0000 - val_mae: 269953.7188\n",
      "Epoch 8/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 84545396736.0000 - mae: 248013.0000 - val_loss: 94125449216.0000 - val_mae: 269950.0938\n",
      "Epoch 9/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 85315608576.0000 - mae: 247111.6250 - val_loss: 94122516480.0000 - val_mae: 269945.5000\n",
      "Epoch 10/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 82783789056.0000 - mae: 244482.3281 - val_loss: 94118707200.0000 - val_mae: 269939.5938\n",
      "Epoch 11/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 85161172992.0000 - mae: 248061.2344 - val_loss: 94113996800.0000 - val_mae: 269932.3125\n",
      "Epoch 12/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 81412390912.0000 - mae: 243419.7969 - val_loss: 94108114944.0000 - val_mae: 269923.3438\n",
      "Epoch 13/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 83863699456.0000 - mae: 247481.7812 - val_loss: 94100946944.0000 - val_mae: 269912.5312\n",
      "Epoch 14/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 83568689152.0000 - mae: 246792.7500 - val_loss: 94092345344.0000 - val_mae: 269899.6250\n",
      "Epoch 15/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 80260415488.0000 - mae: 240287.5625 - val_loss: 94082285568.0000 - val_mae: 269884.6250\n",
      "Epoch 16/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 83083599872.0000 - mae: 249022.5156 - val_loss: 94070513664.0000 - val_mae: 269867.1875\n",
      "Epoch 17/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 81897783296.0000 - mae: 245622.9844 - val_loss: 94057054208.0000 - val_mae: 269847.3125\n",
      "Epoch 18/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 76587204608.0000 - mae: 232407.5625 - val_loss: 94041882624.0000 - val_mae: 269824.9062\n",
      "Epoch 19/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 77167075328.0000 - mae: 234513.1875 - val_loss: 94024466432.0000 - val_mae: 269799.3750\n",
      "Epoch 20/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 83563667456.0000 - mae: 245421.7656 - val_loss: 94004420608.0000 - val_mae: 269770.1875\n",
      "Epoch 21/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 81628110848.0000 - mae: 241557.9219 - val_loss: 93982621696.0000 - val_mae: 269738.4375\n",
      "Epoch 22/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 85652930560.0000 - mae: 249793.3906 - val_loss: 93958037504.0000 - val_mae: 269702.7500\n",
      "Epoch 23/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 80112828416.0000 - mae: 240525.4688 - val_loss: 93931470848.0000 - val_mae: 269664.1250\n",
      "Epoch 24/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 86538207232.0000 - mae: 251536.6719 - val_loss: 93901209600.0000 - val_mae: 269620.4688\n",
      "Epoch 25/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 79220482048.0000 - mae: 241020.0625 - val_loss: 93869645824.0000 - val_mae: 269574.7812\n",
      "Epoch 26/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 72742346752.0000 - mae: 228257.3594 - val_loss: 93834829824.0000 - val_mae: 269524.6562\n",
      "Epoch 27/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 85505228800.0000 - mae: 249237.3750 - val_loss: 93796311040.0000 - val_mae: 269469.3750\n",
      "Epoch 28/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 82160730112.0000 - mae: 245711.1094 - val_loss: 93754802176.0000 - val_mae: 269409.8125\n",
      "Epoch 29/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 82914557952.0000 - mae: 246288.1250 - val_loss: 93710598144.0000 - val_mae: 269346.3750\n",
      "Epoch 30/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 85646934016.0000 - mae: 254350.6094 - val_loss: 93663371264.0000 - val_mae: 269278.7500\n",
      "Epoch 31/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 80649756672.0000 - mae: 239699.1875 - val_loss: 93613531136.0000 - val_mae: 269207.5000\n",
      "Epoch 32/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 84049117184.0000 - mae: 244509.2188 - val_loss: 93558939648.0000 - val_mae: 269129.6250\n",
      "Epoch 33/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 84342235136.0000 - mae: 249245.1406 - val_loss: 93501939712.0000 - val_mae: 269048.1875\n",
      "Epoch 34/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 79149441024.0000 - mae: 238892.3594 - val_loss: 93441974272.0000 - val_mae: 268962.5312\n",
      "Epoch 35/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 80990289920.0000 - mae: 244357.6094 - val_loss: 93376315392.0000 - val_mae: 268869.0000\n",
      "Epoch 36/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 88641208320.0000 - mae: 254273.8438 - val_loss: 93306740736.0000 - val_mae: 268770.2500\n",
      "Epoch 37/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 78167433216.0000 - mae: 237814.2812 - val_loss: 93236166656.0000 - val_mae: 268669.5625\n",
      "Epoch 38/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 81790615552.0000 - mae: 245671.2500 - val_loss: 93160136704.0000 - val_mae: 268561.4062\n",
      "Epoch 39/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 79955746816.0000 - mae: 243906.8438 - val_loss: 93081346048.0000 - val_mae: 268449.3438\n",
      "Epoch 40/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 79119286272.0000 - mae: 238155.6250 - val_loss: 92996714496.0000 - val_mae: 268329.2500\n",
      "Epoch 41/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 77953040384.0000 - mae: 236224.5781 - val_loss: 92908666880.0000 - val_mae: 268204.2812\n",
      "Epoch 42/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 77826531328.0000 - mae: 237523.8906 - val_loss: 92814802944.0000 - val_mae: 268071.1875\n",
      "Epoch 43/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 81466671104.0000 - mae: 244611.6406 - val_loss: 92718317568.0000 - val_mae: 267934.5312\n",
      "Epoch 44/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 81241784320.0000 - mae: 241031.9375 - val_loss: 92616761344.0000 - val_mae: 267790.6875\n",
      "Epoch 45/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 81932615680.0000 - mae: 244507.6406 - val_loss: 92513230848.0000 - val_mae: 267643.7188\n",
      "Epoch 46/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 79889072128.0000 - mae: 242741.4844 - val_loss: 92403744768.0000 - val_mae: 267488.4688\n",
      "Epoch 47/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 74305314816.0000 - mae: 231336.6250 - val_loss: 92290711552.0000 - val_mae: 267328.2500\n",
      "Epoch 48/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 81618518016.0000 - mae: 244614.9531 - val_loss: 92167184384.0000 - val_mae: 267153.7500\n",
      "Epoch 49/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 77852819456.0000 - mae: 238711.4531 - val_loss: 92045238272.0000 - val_mae: 266980.8125\n",
      "Epoch 50/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 76159459328.0000 - mae: 233817.4844 - val_loss: 91917000704.0000 - val_mae: 266799.3750\n",
      "Epoch 51/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 78677049344.0000 - mae: 236997.5312 - val_loss: 91780988928.0000 - val_mae: 266607.0938\n",
      "Epoch 52/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 78318755840.0000 - mae: 238186.3438 - val_loss: 91644952576.0000 - val_mae: 266414.1875\n",
      "Epoch 53/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 73259180032.0000 - mae: 228725.9531 - val_loss: 91502886912.0000 - val_mae: 266212.9375\n",
      "Epoch 54/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 81453645824.0000 - mae: 245397.0625 - val_loss: 91351818240.0000 - val_mae: 265999.0938\n",
      "Epoch 55/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 78976393216.0000 - mae: 237117.5938 - val_loss: 91198808064.0000 - val_mae: 265782.3125\n",
      "Epoch 56/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 81230200832.0000 - mae: 244606.0625 - val_loss: 91041226752.0000 - val_mae: 265559.0312\n",
      "Epoch 57/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 82635350016.0000 - mae: 249437.5469 - val_loss: 90875355136.0000 - val_mae: 265324.1250\n",
      "Epoch 58/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 82430492672.0000 - mae: 246833.7188 - val_loss: 90708836352.0000 - val_mae: 265088.0312\n",
      "Epoch 59/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 78241234944.0000 - mae: 238717.0156 - val_loss: 90540523520.0000 - val_mae: 264848.8750\n",
      "Epoch 60/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 78686273536.0000 - mae: 240355.4688 - val_loss: 90361184256.0000 - val_mae: 264594.0000\n",
      "Epoch 61/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 81733943296.0000 - mae: 244771.7812 - val_loss: 90176757760.0000 - val_mae: 264332.3750\n",
      "Epoch 62/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 82615025664.0000 - mae: 247928.8750 - val_loss: 89988521984.0000 - val_mae: 264064.6250\n",
      "Epoch 63/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 81038811136.0000 - mae: 243688.5781 - val_loss: 89791586304.0000 - val_mae: 263785.0312\n",
      "Epoch 64/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 79454625792.0000 - mae: 238352.9219 - val_loss: 89594421248.0000 - val_mae: 263504.4062\n",
      "Epoch 65/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 75625840640.0000 - mae: 236882.6094 - val_loss: 89391915008.0000 - val_mae: 263215.7188\n",
      "Epoch 66/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 73598582784.0000 - mae: 231432.6094 - val_loss: 89185083392.0000 - val_mae: 262920.9688\n",
      "Epoch 67/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 74811736064.0000 - mae: 234683.4219 - val_loss: 88969977856.0000 - val_mae: 262614.3750\n",
      "Epoch 68/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 77922877440.0000 - mae: 240241.4375 - val_loss: 88749260800.0000 - val_mae: 262299.5000\n",
      "Epoch 69/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 78149337088.0000 - mae: 239850.8438 - val_loss: 88518582272.0000 - val_mae: 261970.2344\n",
      "Epoch 70/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 78183751680.0000 - mae: 240175.3750 - val_loss: 88289525760.0000 - val_mae: 261642.5469\n",
      "Epoch 71/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 76906651648.0000 - mae: 235374.5312 - val_loss: 88053989376.0000 - val_mae: 261305.1562\n",
      "Epoch 72/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 76647841792.0000 - mae: 237567.4062 - val_loss: 87813087232.0000 - val_mae: 260959.5781\n",
      "Epoch 73/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 77173268480.0000 - mae: 237375.2031 - val_loss: 87564001280.0000 - val_mae: 260602.5938\n",
      "Epoch 74/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 76787499008.0000 - mae: 236323.8906 - val_loss: 87316398080.0000 - val_mae: 260246.4531\n",
      "Epoch 75/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 79747842048.0000 - mae: 244828.8438 - val_loss: 87060783104.0000 - val_mae: 259878.8438\n",
      "Epoch 76/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 72806490112.0000 - mae: 229786.3125 - val_loss: 86801317888.0000 - val_mae: 259504.8438\n",
      "Epoch 77/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 77987856384.0000 - mae: 238630.7188 - val_loss: 86524649472.0000 - val_mae: 259106.7188\n",
      "Epoch 78/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 75555897344.0000 - mae: 234767.1250 - val_loss: 86254583808.0000 - val_mae: 258716.4375\n",
      "Epoch 79/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 76840566784.0000 - mae: 237880.2344 - val_loss: 85971861504.0000 - val_mae: 258308.2812\n",
      "Epoch 80/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 74260258816.0000 - mae: 232642.4062 - val_loss: 85689475072.0000 - val_mae: 257899.3438\n",
      "Epoch 81/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 72640028672.0000 - mae: 226364.2969 - val_loss: 85399945216.0000 - val_mae: 257479.5781\n",
      "Epoch 82/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 73103982592.0000 - mae: 228682.9062 - val_loss: 85105885184.0000 - val_mae: 257052.2031\n",
      "Epoch 83/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 72805130240.0000 - mae: 230417.5625 - val_loss: 84805861376.0000 - val_mae: 256616.0625\n",
      "Epoch 84/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 80321454080.0000 - mae: 244785.8438 - val_loss: 84491771904.0000 - val_mae: 256158.7344\n",
      "Epoch 85/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 76001697792.0000 - mae: 236747.0000 - val_loss: 84186677248.0000 - val_mae: 255712.7188\n",
      "Epoch 86/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 73596534784.0000 - mae: 230621.1875 - val_loss: 83877855232.0000 - val_mae: 255261.0625\n",
      "Epoch 87/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 71922286592.0000 - mae: 228456.9219 - val_loss: 83556646912.0000 - val_mae: 254791.1562\n",
      "Epoch 88/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 69632065536.0000 - mae: 224013.4219 - val_loss: 83235053568.0000 - val_mae: 254319.4844\n",
      "Epoch 89/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 74060251136.0000 - mae: 232896.0938 - val_loss: 82897387520.0000 - val_mae: 253824.2031\n",
      "Epoch 90/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 68602892288.0000 - mae: 222866.1250 - val_loss: 82558001152.0000 - val_mae: 253324.5781\n",
      "Epoch 91/100\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "np.random.seed(42)\n",
    "num_samples = 500\n",
    "\n",
    "X = np.random.rand(num_samples, 3) * 100  \n",
    "y = X[:, 0] * 300 + X[:, 1] * 5000 - X[:, 2] * 200 + np.random.randn(num_samples) * 10000  \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(64, activation='relu', input_shape=(3,)), \n",
    "    keras.layers.Dense(32, activation='relu'), \n",
    "    keras.layers.Dense(1)  \n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test), verbose=1)\n",
    "\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.legend()\n",
    "plt.title('Loss Curve for House Price Prediction')\n",
    "plt.show()\n",
    "\n",
    "predictions = model.predict(X_test[:5])\n",
    "print(\"Sample Predictions:\", predictions.flatten())\n",
    "print(\"Actual Prices:\", y_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43602ee6-3038-40c4-8f3b-9721aec85fdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
